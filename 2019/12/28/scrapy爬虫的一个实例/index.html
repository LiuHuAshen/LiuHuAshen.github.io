<!DOCTYPE html>
<html lang="en">
  <head><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="scrapy爬虫的一个实例"/><meta name="keywords" content="前端,开发者,程序猿,Coder" /><link rel="alternate" href="/default" title="LHS'Blogs"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0" />
<link rel="canonical" href="https://LiuHuAshen.github.io/2019/12/28/scrapy爬虫的一个实例/"/>

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0" />

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":"","latex":false};
</script>

    <title>scrapy爬虫的一个实例 - LHS'Blogs</title>
  <meta name="generator" content="Hexo 4.2.0"></head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">LHS'Blogs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">Home
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">LHS'Blogs</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            Home
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">scrapy爬虫的一个实例
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2019-12-28
        </span></div>
    </header>

    <div class="post-content"><p><strong>一:建立一个Scrapy爬虫工程</strong><br>打开cmd:输人scrapy scrapyproject python123,,如下截图:<br>这里输入的意思是定义一个工程,它的名字叫python123.<br><img src="https://img-blog.csdnimg.cn/20191030195534891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hCMTU0NTg3NTU=,size_16,color_FFFFFF,t_70" alt=""></p>
<a id="more"></a>
<p>此时在d盘中可以看到生成的scrapy的工程<br><img src="https://img-blog.csdnimg.cn/20191030195822965.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hCMTU0NTg3NTU=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>介绍上述文件的作用：<br><strong>scrapy.cfg</strong>  这个配置,是将爬虫放在特定的服务器上,并且在服务器配置好相关的操作接口.对于本机使用爬虫,不需要改变部署的配置文件.<br><strong>init.py</strong>  用户不需要编写<br><strong>items.py</strong>  需要继承scrapy库提供的ietms类,对于一般的例子用户不需要编写<br><strong>middlewares.py</strong>  如果用户需要扩展middlewares的功能,则需要编写.<br><strong>pipelines.py</strong>  指的是框架中的pipelines模块<br><strong>settings.py</strong>  指的是Scrapy爬虫的文件,如果需要优化爬虫,则需要设置这个文件对应的配置项.<br><strong>spiders</strong>    是在存放python123demo工程建立的爬虫</p>
<p><strong>二:在工程中产生一个Scrapy爬虫</strong><br>输入命令：scrapy genspider demo python123.io<br><img src="https://img-blog.csdnimg.cn/20191030200217681.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hCMTU0NTg3NTU=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>三、配置产生的spider爬虫</strong><br>在文件当中生成了一个demo.py文件，然后对该文件进行修改，代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DemoSpider(scrapy.Spider):</span><br><span class="line">    name = <span class="string">'demo'</span></span><br><span class="line">    #allowed_domains = ['python123.io']</span><br><span class="line">    start_urls = [<span class="string">'http://python123.io/ws/demo.html'</span>]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        fname=response.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">with</span> open(fname,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Save file %s.'</span> %fname)</span><br></pre></td></tr></table></figure>
<p>1 )是一个面向对象编写的类,这个类叫DemoSpider<br>2 )由于我们的名字叫demo,所以这个类名也叫demospider,名字也可以叫我们任何想叫的名字.<br>3 )这个类必须是继承与scrapy.Spider的子类.<br>4 )这里有个变量叫name,被赋值为demo,说明当前爬虫的名字叫demo.<br>5 )allowed_domains这个是用户提交给命令行的命名.这个爬虫在爬取网站的时候只能爬取这个域名以下的相关链接.<br>6 )start_urls以列表的形式包含一个或多个url就是scrapy框架要爬取的初始页面.<br>7 )def parse是解析页面一个空的方法.<br>8 )pass是处理响应,可以解析从网上爬取的内容,并形成字典类型,同时对网络中爬取的内容发现其中隐含的新的url.</p>
<p>程序的改进，使用yield生成器：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DemoSpider(scrapy.Spider):</span><br><span class="line">    name = <span class="string">'demo'</span></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        urls=[</span><br><span class="line">              <span class="string">'http://python123.io/ws/demo.html'</span></span><br><span class="line">            ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url,callback=self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        fname=response.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">with</span> open(fname,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Save file %s.'</span> %fname)</span><br></pre></td></tr></table></figure>


<p><strong>四、运行爬虫,获取网页</strong><br>在命令行cmd执行这个命令,输入:crapy crawl demo<br><img src="https://img-blog.csdnimg.cn/20191030200823465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hCMTU0NTg3NTU=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>此时，就爬取成功了，在目录下生成了demo.html文件<br><img src="https://img-blog.csdnimg.cn/20191030200905413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hCMTU0NTg3NTU=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>

      </div>
      <div class="post-copyright">
    <p class="copyright-item">
      <span>Author: </span>
      <a href="https://LiuHuAshen.github.io">LHS</a>
    </p>
    <p class="copyright-item">
      <span>Link: </span>
      <a href="https://liuhuashen.github.io/2019/12/28/scrapy%E7%88%AC%E8%99%AB%E7%9A%84%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B/">https://liuhuashen.github.io/2019/12/28/scrapy%E7%88%AC%E8%99%AB%E7%9A%84%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B/</a>
    </p>
    <p class="copyright-item">
      <span>License: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/scrapy/">scrapy</a>
            <a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a>
            </div>
        
        <nav class="post-nav"><a class="next" href="/2019/12/27/MySQL%E7%9A%84%E4%BC%98%E5%8C%96/">
        <span class="next-text nav-default">MySQL的优化</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/ahonn" target="_blank" rel="noopener" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even" target="_blank" rel="noopener">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">LHS</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
